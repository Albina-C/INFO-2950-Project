{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #package for http requests\n",
    "import bs4 # package for html parsing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question\n",
    "Is there a relationship in how happy a country is and the music the people of this country listen to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Attempting to understand what makes a country \"happy\" is often attributable to freedom, social support, life expectancy, health, among others; however, the music the people of said country listen to is often not one of these factors given its weak relationship and versatility across the world. Although our research question does not attempt to attribute the type of music a country listens to to its happiness index score (it would be difficult to establish given reverse causality), we are more interested in observing what trends are apparent in some of the happiest and less happiest countries with respect to the music they listen to. \n",
    "\n",
    "We will be using the happiness rank and happiness score for the year 2017, provided by a dataset on Kaggle by Sustainable Development Solutions Network. As for the music, we will be using two distinct spotify datasets for the year 2017 from Kaggle. We will be using features of one of these datasets, such as genre and danceability score, in order to draw comparisons with our happiness scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy2015=pd.read_csv(\"2015.csv\")\n",
    "happy2016=pd.read_csv(\"2016.csv\")\n",
    "happy2017=pd.read_csv(\"2017.csv\")\n",
    "happy2018=pd.read_csv(\"2018.csv\")\n",
    "happy2019=pd.read_csv(\"2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data 2.csv does not exist: 'data 2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-f6800bff2b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallspotifydata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data 2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallspotifydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mallcountries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data 2.csv does not exist: 'data 2.csv'"
     ]
    }
   ],
   "source": [
    "allspotifydata=pd.read_csv(\"data 2.csv\")\n",
    "countries=pd.unique(allspotifydata['Region'])\n",
    "\n",
    "allcountries=[]\n",
    "for country in countries:\n",
    "    allcountries.append(allspotifydata[allspotifydata['Region']==country])\n",
    "\n",
    "count=1\n",
    "for df in allcountries:\n",
    "    name='country'+str(count)+'.csv'\n",
    "    df.to_csv(r'C:\\Users\\Eva\\Downloads\\country'+str(count)+'.csv')\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argentina=pd.read_csv(\"argentina.csv\")\n",
    "australia=pd.read_csv(\"australia.csv\")\n",
    "austria=pd.read_csv(\"austria.csv\")\n",
    "belgium=pd.read_csv(\"belgium.csv\")\n",
    "bolivia=pd.read_csv(\"bolivia.csv\")\n",
    "brazil=pd.read_csv(\"brazil.csv\")\n",
    "canada=pd.read_csv(\"canada.csv\")\n",
    "chile=pd.read_csv(\"chile.csv\")\n",
    "colombia=pd.read_csv(\"colombia.csv\")\n",
    "costarica=pd.read_csv(\"costarica.csv\")\n",
    "czechrepublic=pd.read_csv(\"czechrepublic.csv\")\n",
    "denmark=pd.read_csv(\"denmark.csv\")\n",
    "dominicanrepublic=pd.read_csv(\"dominicanrepublic.csv\")\n",
    "ecuador=pd.read_csv(\"ecuador.csv\")\n",
    "elsalvador=pd.read_csv('elsalvador.csv')\n",
    "estonia=pd.read_csv('estonia.csv')\n",
    "finland=pd.read_csv(\"finland.csv\")\n",
    "france=pd.read_csv(\"france.csv\")\n",
    "germany=pd.read_csv(\"germany.csv\")\n",
    "Global=pd.read_csv('global.csv')\n",
    "greece=pd.read_csv('greece.csv')\n",
    "guatemala=pd.read_csv(\"guatemala.csv\")\n",
    "honduras=pd.read_csv(\"honduras.csv\")\n",
    "hongkong=pd.read_csv(\"hongkong.csv\")\n",
    "hungary=pd.read_csv(\"hungary.csv\")\n",
    "iceland=pd.read_csv(\"iceland.csv\")\n",
    "indonesia=pd.read_csv(\"indonesia.csv\")\n",
    "ireland=pd.read_csv(\"ireland.csv\")\n",
    "italy=pd.read_csv(\"italy.csv\")\n",
    "japan=pd.read_csv(\"japan.csv\")\n",
    "latvia=pd.read_csv(\"latvia.csv\")\n",
    "lithuania=pd.read_csv(\"lithuania.csv\")\n",
    "luxembourg=pd.read_csv(\"luxembourg.csv\")\n",
    "malaysia=pd.read_csv(\"malaysia.csv\")\n",
    "mexico=pd.read_csv(\"mexico.csv\")\n",
    "netherlands=pd.read_csv(\"netherlands.csv\")\n",
    "newzealand=pd.read_csv(\"newzealand.csv\")\n",
    "norway=pd.read_csv(\"norway.csv\")\n",
    "panama=pd.read_csv(\"panama.csv\")\n",
    "paraguay=pd.read_csv(\"paraguay.csv\")\n",
    "peru=pd.read_csv(\"peru.csv\")\n",
    "philippines=pd.read_csv(\"philippines.csv\")\n",
    "poland=pd.read_csv(\"poland.csv\")\n",
    "portugal=pd.read_csv(\"portugal.csv\")\n",
    "singapore=pd.read_csv(\"singapore.csv\")\n",
    "slovakia=pd.read_csv(\"slovakia.csv\")\n",
    "spain=pd.read_csv(\"spain.csv\")\n",
    "sweden=pd.read_csv(\"sweden.csv\")\n",
    "switzerland=pd.read_csv(\"switzerland.csv\")\n",
    "taiwan=pd.read_csv(\"taiwan.csv\")\n",
    "turkey=pd.read_csv(\"turkey.csv\")\n",
    "unitedkingdom=pd.read_csv(\"unitedkingdom.csv\")\n",
    "unitedstates=pd.read_csv(\"unitedstates.csv\")\n",
    "uruguay=pd.read_csv(\"uruguay.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allspotifycountries=[\"argentina\", \"australia\", \"austria\", \"belgium\", \"brazil\",\"bolivia\", \"canada\", \"chile\", \"colombia\", \"costarica\", \"czechrepublic\",\"denmark\", \"dominicanrepublic\", \"estonia\", \"elsalvador\", \"Global\",\"greece\", \"ecuador\", \"finland\", \"france\", \"germany\", \"guatemala\", \"honduras\", \"hongkong\", \"hungary\", \"iceland\", \"indonesia\", \"ireland\", \"italy\", \"japan\", \"latvia\", \"lithuania\", \"luxembourg\", \"malaysia\", \"mexico\", \"netherlands\", \"newzealand\", \"norway\", \"panama\", \"paraguay\", \"peru\", \"philippines\", \"poland\", \"portugal\", \"singapore\", \"slovakia\", \"spain\", \"sweden\", \"switzerland\", \"taiwan\", \"turkey\", \"unitedkingdom\", \"unitedstates\", \"uruguay\"]\n",
    "\n",
    "#list for countries that are found in both datsets.\n",
    "allcountries=[]\n",
    "for row in range(len(happy2017)):\n",
    "    country=happy2017.loc[row,'Country']\n",
    "    country=country.lower()\n",
    "    country=country.replace(\" \",\"\")\n",
    "    if country in allspotifycountries:\n",
    "        allcountries.append(country)      \n",
    "\n",
    "#Happy Index from 2017 with only 'Country', 'Happiness.Rank', and 'Happiness.Score' columns and only with countries that have their own dataset for spotify daily.        \n",
    "happy=pd.DataFrame({'Country':[],'Happiness.Rank':[],'Happiness.Score':[]})\n",
    "for row in range(len(happy2017)):\n",
    "    country=happy2017.loc[row,'Country']\n",
    "    country=country.lower()\n",
    "    country=country.replace(\" \",\"\")\n",
    "    if country in allcountries:       \n",
    "        newrow={'Country':happy2017.loc[row,'Country'],'Happiness.Rank':happy2017.loc[row,'Happiness.Rank'],'Happiness.Score':happy2017.loc[row,'Happiness.Score']}\n",
    "        happy=happy.append(newrow, ignore_index=True)\n",
    "\n",
    "        \n",
    "#Noticed that Taiwan is referred to as Taiwan Province of China on Happy Index.\n",
    "newrow={'Country':happy2017.loc[32,'Country'],'Happiness.Rank':happy2017.loc[32,'Happiness.Rank'],'Happiness.Score':happy2017.loc[32,'Happiness.Score']}\n",
    "happy=happy.append(newrow, ignore_index=True)\n",
    "\n",
    "#allspotifydata[allspotifydata['Region']==country])\n",
    "allcountries.append(\"Taiwan\")\n",
    "print('These are the spotify datsets we should use: ' + str(allcountries))\n",
    "print(happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're not using this function yet\n",
    "def firstfifty_fake(dataframe):\n",
    "    \"\"\"\n",
    "    This will get the first 50 observations in every 200 observations.\n",
    "    there are 200 observations in 1 day, and there are 365 days.\n",
    "    \"\"\"\n",
    "    acc=0\n",
    "    new=[]\n",
    "    for song in dataframe:\n",
    "        print(song)\n",
    "        new_songs = dataframe.iloc[acc:acc+50]\n",
    "        acc+=200\n",
    "        dataframe =new_songs\n",
    "        new.append(new_songs)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief Explanation of Code Above\n",
    "This is a similar function to the one encountered below; however, this does not quite fulfill our desire goal, so we have just lef it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the countries we will work with based on the subset below in allcountries. We will use this to subset the first 50 songs below\n",
    "countries_to_subset = [norway, denmark, iceland, switzerland, finland, \n",
    "                       netherlands, canada, newzealand, sweden, australia, costarica, austria, \n",
    "                       unitedstates, ireland, germany, belgium, luxembourg, unitedkingdom, \n",
    "                       chile, brazil, czechrepublic, argentina, mexico, singapore, uruguay, guatemala,\n",
    "                       panama, france, spain, colombia, slovakia, malaysia, ecuador, elsalvador, poland, \n",
    "                       italy, japan,lithuania, latvia, bolivia, peru, estonia, turkey, paraguay, \n",
    "                       philippines, hungary, indonesia, dominicanrepublic, greece, portugal, honduras, taiwan]\n",
    "\n",
    "countries_to_subset_str = ['norway', 'denmark', 'iceland', 'switzerland', 'finland', 'netherlands', \n",
    "                           'canada', 'newzealand', 'sweden', 'australia', 'costarica', 'austria', \n",
    "                           'unitedstates', 'ireland', 'germany', 'belgium', 'luxembourg', 'unitedkingdom', \n",
    "                           'chile', 'brazil', 'czechrepublic', 'argentina', 'mexico', 'singapore', \n",
    "                           'uruguay', 'guatemala', 'panama', 'france', 'spain', 'colombia', 'slovakia', \n",
    "                           'malaysia', 'ecuador', 'elsalvador', 'poland', 'italy', 'japan', 'lithuania',\n",
    "                           'latvia', 'bolivia', 'peru', 'estonia', 'turkey', 'paraguay', 'philippines', \n",
    "                           'hungary', 'indonesia', 'dominicanrepublic', 'greece', 'portugal', 'honduras', 'Taiwan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief Explanation of Code Above\n",
    "This part is collecting a list of all the \"usable\" countries' dataframes, as determined by the subset above in which happiness rank is compared to the spotify dataset. It collects these dataframes to then use them in a for-loop below. We are also taking a list of the selfsame countries in string form to work with their names for purposes later in our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_norway = norway.groupby(norway.index//200).head(50)\n",
    "def first_fifty(dataframe):\n",
    "    \"\"\"\n",
    "    This will get the first 50 observations in every 200 observations.\n",
    "    There should only be 200 observations in 1 day, and there are 365 days per country in this data,\n",
    "    which is the purpose of this function.\n",
    "    \n",
    "    Parameter dataframe: this is the countrydatafram which we will work with.\n",
    "    Precondition: a pandas dataframe object\n",
    "    \"\"\"\n",
    "    subset_data = dataframe.groupby(dataframe.index//200).head(50) \n",
    "    dataframe = subset_data.copy()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief Explanation of Code Above\n",
    "A function meant to subset the first fifty observations of every 200 songs in our dataset as otherwise we would be working with 200 songs x 265 days, which is excessive for our analysis – and memory – purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for country in countries_to_subset:\n",
    "# #     new_name = str(country)+ '1'\n",
    "# #     new_name = first_fifty(country)\n",
    "#     str(country)= first_fifty(country)\n",
    "norway1 = first_fifty(norway)\n",
    "denmark1= first_fifty(denmark)\n",
    "iceland1 = first_fifty(iceland)\n",
    "switzerland1= first_fifty(switzerland)\n",
    "finland1 = first_fifty(finland)\n",
    "netherlands1= first_fifty(netherlands)\n",
    "canada1 = first_fifty(canada)\n",
    "newzealand1= first_fifty(newzealand)\n",
    "sweden1= first_fifty(sweden)\n",
    "australia1= first_fifty(australia)\n",
    "costarica1= first_fifty(costarica)\n",
    "austria1 = first_fifty(austria)\n",
    "unitedstates1= first_fifty(unitedstates)\n",
    "ireland1= first_fifty(ireland)\n",
    "germany1= first_fifty(germany)\n",
    "belgium1= first_fifty(belgium)\n",
    "luxembourg1= first_fifty(luxembourg)\n",
    "unitedkingdom1= first_fifty(unitedkingdom)\n",
    "chile1= first_fifty(chile)\n",
    "brazil1= first_fifty(brazil)\n",
    "czechrepublic1= first_fifty(czechrepublic)\n",
    "argentina1= first_fifty(argentina)\n",
    "mexico1= first_fifty(mexico)\n",
    "singapore1= first_fifty(singapore)\n",
    "uruguay1= first_fifty(uruguay)\n",
    "guatemala1= first_fifty(guatemala)\n",
    "panama1= first_fifty(panama)\n",
    "france1= first_fifty(france)\n",
    "spain1= first_fifty(spain)\n",
    "colombia1= first_fifty(colombia)\n",
    "slovakia1= first_fifty(slovakia)\n",
    "malaysia1= first_fifty(malaysia)\n",
    "ecuador1= first_fifty(ecuador)\n",
    "elsalvador1= first_fifty(elsalvador)\n",
    "poland1= first_fifty(poland)\n",
    "italy1= first_fifty(italy)\n",
    "japan1= first_fifty(japan)\n",
    "lithuania1= first_fifty(lithuania)\n",
    "latvia1= first_fifty(latvia)\n",
    "bolivia1= first_fifty(bolivia)\n",
    "peru1= first_fifty(peru)\n",
    "estonia1= first_fifty(estonia)\n",
    "turkey1= first_fifty(turkey)\n",
    "paraguay1= first_fifty(paraguay)\n",
    "philippines1= first_fifty(philippines)\n",
    "hungary1= first_fifty(hungary)\n",
    "indonesia1= first_fifty(indonesia)\n",
    "dominicanrepublic1= first_fifty(dominicanrepublic)\n",
    "greece1= first_fifty(greece)\n",
    "portugal1= first_fifty(portugal)\n",
    "honduras1= first_fifty(honduras)\n",
    "taiwan1= first_fifty(taiwan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief Explanation of Code Above\n",
    "This part is attaching these new subsetted dataframes to each country's name and adding 1 to it, as to not alter the original dataframe.\n",
    "\n",
    "Ex: The original Norway dataframe contains all the subsetted data of 50 observations for every 200 songs (day) in the now-new dataframe Norway1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "1) Given we are dealing with a relatively sample of only 2017, albeit with 50 songs per day, drawing conclusions for what type of music a happy or unhappy country listens may not prove out to be as accurate as we would like it to be. We can say, however, that the culture of a country likely does not vary signficantly from one year to another, so the top genres and happy scores may reflect of the country's values to an extent.\n",
    "\n",
    "2) Some countries were omitted in order to be able to use the countries in the happiness index and those in our spotify data. In order to draw some observations, we had to find overlap in songs. This may naturally produce bias since some potentially happy countries with potentially signficant relationships to music will completely be overlooked due to availability of data. This concerns mainly the overarching/big picture of happy countries and certain genres being more common.\n",
    "\n",
    "3) We are relying on the genre and danceability score for specific songs provided by a dataset. It is possible this dataset contains subjective information to the user, hence the genres and danceability scores may not reflect the names the people of the country would utilize. This metric of genre, further, may be interpreted as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
