{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #package for http requests\n",
    "import bs4\n",
    "# from bs4 import BeautifulSoup # package for html parsing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "import sqlalchemy\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following two functions were taken from this website. we have modified them slightly\n",
    "# https://gist.github.com/hktosun/d4f98488cb8f005214acd12296506f48\n",
    "def daterange(start_date, end_date):\n",
    "    '''\n",
    "    helper function for create_links\n",
    "    '''\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "# It creates the list of page links we will get the data from.\n",
    "def create_links_2020(country):\n",
    "    '''\n",
    "    returns an array of strings, which are 365 links to spotify charts for each day in 2020 for a specified country.\n",
    "    parameter: a string, postal id for a country. eg. to get 365 links for the united states, call create_links('us')\n",
    "    '''\n",
    "    start_date = date(2020, 1, 1)\n",
    "    end_date = date(2020,12,31)\n",
    "    links = []\n",
    "    dates = daterange(start_date, end_date)\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        links.append('https://spotifycharts.com/regional/' + country + '/daily/' + single_date.strftime(\"%Y-%m-%d\"))\n",
    "    return(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #demonstration of code\n",
    "# links_us=create_links_2020('us')\n",
    "# print(len(links_us))\n",
    "# links_us[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_links_2017(country):\n",
    "    start_date = date(2017, 1, 1)\n",
    "    end_date = date(2017,12,31)\n",
    "    links = []\n",
    "    dates = daterange(start_date, end_date)\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        links.append('https://spotifycharts.com/regional/' + country + '/daily/' + single_date.strftime(\"%Y-%m-%d\"))\n",
    "    return(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(link):\n",
    "    '''\n",
    "    a function that returns a table of the top 50 songs from a spotify chart\n",
    "    with the following columns:\n",
    "    track. a string, \"[track name] by [artist]\"\n",
    "    position. an int, the ranking of the track on the chart.\n",
    "    streams. an int, # of streams of the track on a specified date.\n",
    "    date. a date time obj. the day the song was streamed.\n",
    "    url. a url to the song on Spotify.\n",
    "    \n",
    "    argument: a string, which is a link to a Spotify chart. eg. 'https://spotifycharts.com/regional/us/daily/2020-01-01'\n",
    "    '''\n",
    "    #getting the df\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    r = scraper.get(link)\n",
    "    df_list = pd.read_html(r.text) # this parses all the tables in webpages to a lis\n",
    "    df = df_list[0]\n",
    "    #for the purposes of our project, we only want the top 50 songs of the table that was scraped from the\n",
    "    #spotify website, which gives us top 200. we find that 200 songs per day was excessive\n",
    "    df=df.head(50)\n",
    "\n",
    "    #cleaning column names and dropping irrelevant columns\n",
    "    #to lowercase\n",
    "    cols= [x.lower() for x in df.columns] \n",
    "    df.columns=cols\n",
    "    #after scraping, Spotify returns a column 'unnamed: 1', which is actually the position of the song on the chart.\n",
    "    #which we have renamed\n",
    "    df = df.rename(columns={'unnamed: 1': 'position'})\n",
    "    #it also returns two NaN columns, which we drop here\n",
    "    df=df.drop(columns=[\"unnamed: 0\",\"unnamed: 2\"])\n",
    "    \n",
    "    #adding a date column by parsing the link used in the argument.\n",
    "    df[\"date\"]=link[-10:]\n",
    "    df['date']=pd.to_datetime(df['date'])\n",
    "    \n",
    "    #creating the url column\n",
    "    #using Beautiful soup to webscrape the links on the site.\n",
    "    datasoup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    aList=[]\n",
    "    #find all 'a' tags\n",
    "    for data in datasoup.findAll('a'):\n",
    "        aList.append(data)\n",
    "    links=[]\n",
    "    #find all href tags\n",
    "    for x in aList:\n",
    "        links.append(x.get('href'))\n",
    "    #drop None types\n",
    "    clean = filter(None, links)\n",
    "    urls=[]\n",
    "    #only keep the links that are links to spotify tracks.\n",
    "    for x in clean:\n",
    "        if 'open.spotify.com/track/' in x:\n",
    "            urls.append(x)\n",
    "    #only append the top 50 to the dataframe\n",
    "    df['url']=urls[:50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_artist(df):\n",
    "    '''\n",
    "    returns a df that takes \"track\" column, which contains both the artist and song. \n",
    "    it is a string formatted as \"[track name] by [artist]\"\n",
    "    and parses it into 2 columns: track_name and artist.\n",
    "    and deletes the track column after.\n",
    "    \n",
    "    argument: a dataframe created by get_table(), containing a column \"track\"\n",
    "    with each observation a string formatted as \"[track name] by [artist]\"\n",
    "    '''\n",
    "    tracks=df.track.values\n",
    "    songtitles=[]\n",
    "    songartists=[]\n",
    "    for song in tracks:\n",
    "        index1=song.find(\"  by\")\n",
    "        index2=song.find(\"by \")\n",
    "        track=song[:index1]\n",
    "        songtitles.append(track)\n",
    "        artist=song[index2+3:]\n",
    "        songartists.append(artist)\n",
    "    df[\"track_name\"]=songtitles\n",
    "    df[\"artist\"]=songartists\n",
    "    df=df.drop(columns=[\"track\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcountries=[\"United States\", \"United Kingdom\", \"United Arab Emirates\", \"Argentina\", \"Austria\", \"Australia\", \"Belgium\", \"Bulgaria\", \"Bolivia\", \"Brazil\", \"Canada\", \"Switzerland\", \"Chile\", \"Colombia\", \"Costa Rica\", \"Cyprus\", \"Czech Republic\", \"Germany\", \"Denmark\", \"Dominican Republic\", \"Ecuador\", \"Estonia\", \"Egypt\", \"Spain\", \"Finland\", \"France\", \"Greece\", \"Guatemala\", \"Hong Kong\", \"Honduras\", \"Hungary\", \"Indonesia\", \"Ireland\", \"Israel\", \"India\", \"Iceland\", \"Italy\", \"Japan\", \"Republic of Korea\", \"Lithuania\", \"Luxembourg\", \"Latvia\", \"Morocco\", \"Mexico\", \"Malaysia\", \"Nicaragua\", \"Netherlands\", \"Norway\", \"New Zealand\", \"Panama\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Paraguay\", \"Romania\", \"Russia\", \"Saudi Arabia\", \"Sweden\", \"Singapore\", \"Slovakia\", \"El Salvador\", \"Thailand\", \"Turkey\", \"Taiwan\", \"Ukraine\", \"Uruguay\", \"Vietnam\", \"South Africa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>regional_indicator</th>\n",
       "      <th>ladder_score</th>\n",
       "      <th>standard_error_of_ladder_score</th>\n",
       "      <th>upperwhisker</th>\n",
       "      <th>lowerwhisker</th>\n",
       "      <th>logged_gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "      <th>ladder_score_in_dystopia</th>\n",
       "      <th>explained_by:_log_gdp_per_capita</th>\n",
       "      <th>explained_by:_social_support</th>\n",
       "      <th>explained_by:_healthy_life_expectancy</th>\n",
       "      <th>explained_by:_freedom_to_make_life_choices</th>\n",
       "      <th>explained_by:_generosity</th>\n",
       "      <th>explained_by:_perceptions_of_corruption</th>\n",
       "      <th>dystopia_+_residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.8087</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>7.869766</td>\n",
       "      <td>7.747634</td>\n",
       "      <td>10.639267</td>\n",
       "      <td>0.954330</td>\n",
       "      <td>71.900825</td>\n",
       "      <td>0.949172</td>\n",
       "      <td>-0.059482</td>\n",
       "      <td>0.195445</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.285190</td>\n",
       "      <td>1.499526</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>0.662317</td>\n",
       "      <td>0.159670</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>2.762835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.6456</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>7.711245</td>\n",
       "      <td>7.579955</td>\n",
       "      <td>10.774001</td>\n",
       "      <td>0.955991</td>\n",
       "      <td>72.402504</td>\n",
       "      <td>0.951444</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>0.168489</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.326949</td>\n",
       "      <td>1.503449</td>\n",
       "      <td>0.979333</td>\n",
       "      <td>0.665040</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.495260</td>\n",
       "      <td>2.432741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.5599</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>7.628528</td>\n",
       "      <td>7.491272</td>\n",
       "      <td>10.979933</td>\n",
       "      <td>0.942847</td>\n",
       "      <td>74.102448</td>\n",
       "      <td>0.921337</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>0.303728</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.390774</td>\n",
       "      <td>1.472403</td>\n",
       "      <td>1.040533</td>\n",
       "      <td>0.628954</td>\n",
       "      <td>0.269056</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>2.350267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.5045</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>7.621347</td>\n",
       "      <td>7.387653</td>\n",
       "      <td>10.772559</td>\n",
       "      <td>0.974670</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.246944</td>\n",
       "      <td>0.711710</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.326502</td>\n",
       "      <td>1.547567</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>0.661981</td>\n",
       "      <td>0.362330</td>\n",
       "      <td>0.144541</td>\n",
       "      <td>2.460688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.4880</td>\n",
       "      <td>0.034837</td>\n",
       "      <td>7.556281</td>\n",
       "      <td>7.419719</td>\n",
       "      <td>11.087804</td>\n",
       "      <td>0.952487</td>\n",
       "      <td>73.200783</td>\n",
       "      <td>0.955750</td>\n",
       "      <td>0.134533</td>\n",
       "      <td>0.263218</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.424207</td>\n",
       "      <td>1.495173</td>\n",
       "      <td>1.008072</td>\n",
       "      <td>0.670201</td>\n",
       "      <td>0.287985</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>2.168266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name regional_indicator  ladder_score  \\\n",
       "0      Finland     Western Europe        7.8087   \n",
       "1      Denmark     Western Europe        7.6456   \n",
       "2  Switzerland     Western Europe        7.5599   \n",
       "3      Iceland     Western Europe        7.5045   \n",
       "4       Norway     Western Europe        7.4880   \n",
       "\n",
       "   standard_error_of_ladder_score  upperwhisker  lowerwhisker  \\\n",
       "0                        0.031156      7.869766      7.747634   \n",
       "1                        0.033492      7.711245      7.579955   \n",
       "2                        0.035014      7.628528      7.491272   \n",
       "3                        0.059616      7.621347      7.387653   \n",
       "4                        0.034837      7.556281      7.419719   \n",
       "\n",
       "   logged_gdp_per_capita  social_support  healthy_life_expectancy  \\\n",
       "0              10.639267        0.954330                71.900825   \n",
       "1              10.774001        0.955991                72.402504   \n",
       "2              10.979933        0.942847                74.102448   \n",
       "3              10.772559        0.974670                73.000000   \n",
       "4              11.087804        0.952487                73.200783   \n",
       "\n",
       "   freedom_to_make_life_choices  generosity  perceptions_of_corruption  \\\n",
       "0                      0.949172   -0.059482                   0.195445   \n",
       "1                      0.951444    0.066202                   0.168489   \n",
       "2                      0.921337    0.105911                   0.303728   \n",
       "3                      0.948892    0.246944                   0.711710   \n",
       "4                      0.955750    0.134533                   0.263218   \n",
       "\n",
       "   ladder_score_in_dystopia  explained_by:_log_gdp_per_capita  \\\n",
       "0                  1.972317                          1.285190   \n",
       "1                  1.972317                          1.326949   \n",
       "2                  1.972317                          1.390774   \n",
       "3                  1.972317                          1.326502   \n",
       "4                  1.972317                          1.424207   \n",
       "\n",
       "   explained_by:_social_support  explained_by:_healthy_life_expectancy  \\\n",
       "0                      1.499526                               0.961271   \n",
       "1                      1.503449                               0.979333   \n",
       "2                      1.472403                               1.040533   \n",
       "3                      1.547567                               1.000843   \n",
       "4                      1.495173                               1.008072   \n",
       "\n",
       "   explained_by:_freedom_to_make_life_choices  explained_by:_generosity  \\\n",
       "0                                    0.662317                  0.159670   \n",
       "1                                    0.665040                  0.242793   \n",
       "2                                    0.628954                  0.269056   \n",
       "3                                    0.661981                  0.362330   \n",
       "4                                    0.670201                  0.287985   \n",
       "\n",
       "   explained_by:_perceptions_of_corruption  dystopia_+_residual  \n",
       "0                                 0.477857             2.762835  \n",
       "1                                 0.495260             2.432741  \n",
       "2                                 0.407946             2.350267  \n",
       "3                                 0.144541             2.460688  \n",
       "4                                 0.434101             2.168266  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finland',\n",
       " 'Denmark',\n",
       " 'Switzerland',\n",
       " 'Iceland',\n",
       " 'Norway',\n",
       " 'Netherlands',\n",
       " 'Sweden',\n",
       " 'New Zealand',\n",
       " 'Austria',\n",
       " 'Luxembourg',\n",
       " 'Malaysia',\n",
       " 'Vietnam',\n",
       " 'Indonesia',\n",
       " 'Turkey',\n",
       " 'Bulgaria',\n",
       " 'Morocco',\n",
       " 'South Africa',\n",
       " 'Ukraine',\n",
       " 'Egypt',\n",
       " 'India']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy2020=pd.read_csv('happiness2020.csv')\n",
    "# cols2020= [x.lower() for x in happy2020.columns] \n",
    "# cols2020= [x.replace(\" \",\"_\") for x in cols2020] \n",
    "happy2020.columns=cols2020\n",
    "countries2020=happy2020.country_name.to_numpy()\n",
    "countries2020\n",
    "# countries2020= [x.lower() for x in countries2020] \n",
    "# countries2020= [x.replace(\" \",\"\") for x in countries2020]\n",
    "new=[]\n",
    "for x in countries2020:\n",
    "    if x in allcountries:\n",
    "        new.append(x)\n",
    "topbot2020=new[:10]+new[-10:]\n",
    "topbot2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_id2020=['fi','dk','ch','is','no','nl','se','nz','at','lu','my','vn','id','tr','bg','ma','za','ua','eg','in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Happiness.Rank</th>\n",
       "      <th>Happiness.Score</th>\n",
       "      <th>Whisker.high</th>\n",
       "      <th>Whisker.low</th>\n",
       "      <th>Economy..GDP.per.Capita.</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health..Life.Expectancy.</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Trust..Government.Corruption.</th>\n",
       "      <th>Dystopia.Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>1</td>\n",
       "      <td>7.537</td>\n",
       "      <td>7.594445</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>2.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.522</td>\n",
       "      <td>7.581728</td>\n",
       "      <td>7.462272</td>\n",
       "      <td>1.482383</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.626007</td>\n",
       "      <td>0.355280</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>2.313707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.504</td>\n",
       "      <td>7.622030</td>\n",
       "      <td>7.385970</td>\n",
       "      <td>1.480633</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.627163</td>\n",
       "      <td>0.475540</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>2.322715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.494</td>\n",
       "      <td>7.561772</td>\n",
       "      <td>7.426227</td>\n",
       "      <td>1.564980</td>\n",
       "      <td>1.516912</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.290549</td>\n",
       "      <td>0.367007</td>\n",
       "      <td>2.276716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5</td>\n",
       "      <td>7.469</td>\n",
       "      <td>7.527542</td>\n",
       "      <td>7.410458</td>\n",
       "      <td>1.443572</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>2.430182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>151</td>\n",
       "      <td>3.471</td>\n",
       "      <td>3.543030</td>\n",
       "      <td>3.398970</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>0.945707</td>\n",
       "      <td>0.326425</td>\n",
       "      <td>0.581844</td>\n",
       "      <td>0.252756</td>\n",
       "      <td>0.455220</td>\n",
       "      <td>0.540061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Syria</td>\n",
       "      <td>152</td>\n",
       "      <td>3.462</td>\n",
       "      <td>3.663669</td>\n",
       "      <td>3.260331</td>\n",
       "      <td>0.777153</td>\n",
       "      <td>0.396103</td>\n",
       "      <td>0.500533</td>\n",
       "      <td>0.081539</td>\n",
       "      <td>0.493664</td>\n",
       "      <td>0.151347</td>\n",
       "      <td>1.061574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>153</td>\n",
       "      <td>3.349</td>\n",
       "      <td>3.461430</td>\n",
       "      <td>3.236570</td>\n",
       "      <td>0.511136</td>\n",
       "      <td>1.041990</td>\n",
       "      <td>0.364509</td>\n",
       "      <td>0.390018</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.066035</td>\n",
       "      <td>0.621130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>154</td>\n",
       "      <td>2.905</td>\n",
       "      <td>3.074690</td>\n",
       "      <td>2.735310</td>\n",
       "      <td>0.091623</td>\n",
       "      <td>0.629794</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.059901</td>\n",
       "      <td>0.204435</td>\n",
       "      <td>0.084148</td>\n",
       "      <td>1.683024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>155</td>\n",
       "      <td>2.693</td>\n",
       "      <td>2.864884</td>\n",
       "      <td>2.521116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.270842</td>\n",
       "      <td>0.280876</td>\n",
       "      <td>0.056565</td>\n",
       "      <td>2.066005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Country  Happiness.Rank  Happiness.Score  Whisker.high  \\\n",
       "0                      Norway               1            7.537      7.594445   \n",
       "1                     Denmark               2            7.522      7.581728   \n",
       "2                     Iceland               3            7.504      7.622030   \n",
       "3                 Switzerland               4            7.494      7.561772   \n",
       "4                     Finland               5            7.469      7.527542   \n",
       "..                        ...             ...              ...           ...   \n",
       "150                    Rwanda             151            3.471      3.543030   \n",
       "151                     Syria             152            3.462      3.663669   \n",
       "152                  Tanzania             153            3.349      3.461430   \n",
       "153                   Burundi             154            2.905      3.074690   \n",
       "154  Central African Republic             155            2.693      2.864884   \n",
       "\n",
       "     Whisker.low  Economy..GDP.per.Capita.    Family  \\\n",
       "0       7.479556                  1.616463  1.533524   \n",
       "1       7.462272                  1.482383  1.551122   \n",
       "2       7.385970                  1.480633  1.610574   \n",
       "3       7.426227                  1.564980  1.516912   \n",
       "4       7.410458                  1.443572  1.540247   \n",
       "..           ...                       ...       ...   \n",
       "150     3.398970                  0.368746  0.945707   \n",
       "151     3.260331                  0.777153  0.396103   \n",
       "152     3.236570                  0.511136  1.041990   \n",
       "153     2.735310                  0.091623  0.629794   \n",
       "154     2.521116                  0.000000  0.000000   \n",
       "\n",
       "     Health..Life.Expectancy.   Freedom  Generosity  \\\n",
       "0                    0.796667  0.635423    0.362012   \n",
       "1                    0.792566  0.626007    0.355280   \n",
       "2                    0.833552  0.627163    0.475540   \n",
       "3                    0.858131  0.620071    0.290549   \n",
       "4                    0.809158  0.617951    0.245483   \n",
       "..                        ...       ...         ...   \n",
       "150                  0.326425  0.581844    0.252756   \n",
       "151                  0.500533  0.081539    0.493664   \n",
       "152                  0.364509  0.390018    0.354256   \n",
       "153                  0.151611  0.059901    0.204435   \n",
       "154                  0.018773  0.270842    0.280876   \n",
       "\n",
       "     Trust..Government.Corruption.  Dystopia.Residual  \n",
       "0                         0.315964           2.277027  \n",
       "1                         0.400770           2.313707  \n",
       "2                         0.153527           2.322715  \n",
       "3                         0.367007           2.276716  \n",
       "4                         0.382612           2.430182  \n",
       "..                             ...                ...  \n",
       "150                       0.455220           0.540061  \n",
       "151                       0.151347           1.061574  \n",
       "152                       0.066035           0.621130  \n",
       "153                       0.084148           1.683024  \n",
       "154                       0.056565           2.066005  \n",
       "\n",
       "[155 rows x 12 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id2017=['no', 'dk', 'ch', 'fi', 'nl', 'se', 'ee', 'hu', 'id', 'is', 'ca',\n",
    "       'nz', 'au', 'tr', 'py', 'ph', 'do', 'gy', 'pt', 'hn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id2020=['no', 'dk', 'ch', 'fi', 'nl', 'se', 'ee', 'hu', 'id', 'is', 'ca',\n",
    "       'nz', 'au', 'tr', 'py', 'ph', 'do', 'gy', 'pt', 'hn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Eva run this one\n",
    "# spotify2017=pd.DataFrame()\n",
    "# for region in region_id2017:\n",
    "#     links=create_links_2017(region)\n",
    "#     for link in links:\n",
    "#         df=get_table(link)\n",
    "#         df=track_artist(df)\n",
    "#         df['region']=region\n",
    "#         spotify2020=spotify2020.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-8fbf04b4fe0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_links_2020\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_artist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'region'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-b4ec2c100f00>\u001b[0m in \u001b[0;36mget_table\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#getting the df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mscraper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcloudscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_scraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mdf_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this parses all the tables in webpages to a lis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cloudscraper\\__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         response = self.decodeBrotli(\n\u001b[1;32m--> 263\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         )\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cloudscraper\\__init__.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperform_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCloudScraper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# ------------------------------------------------------------------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Estelle run this one\n",
    "spotify2020=pd.DataFrame()\n",
    "for region in region_id2020:\n",
    "    links=create_links_2020(region)\n",
    "    for link in links:\n",
    "        df=get_table(link)\n",
    "        df=track_artist(df)\n",
    "        df['region']=region\n",
    "        spotify2020=spotify2020.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n",
      "Please enable cookies.\n",
      "\n",
      "\n",
      "One more step\n",
      "Please complete the security check to access spotifycharts.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Please stand by, while we are checking your browser...\n",
      "Redirecting...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Please turn JavaScript on and reload the page.\n",
      "\n",
      "\n",
      "Please enable Cookies and reload the page.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Why do I have to complete a CAPTCHA?\n",
      "\n",
      "Completing the CAPTCHA proves you are a human and gives you temporary access to the web property.\n",
      "\n",
      "\n",
      "What can I do to prevent this in the future?\n",
      "If you are on a personal connection, like at home, you can run an anti-virus scan on your device to make sure it is not infected with malware.\n",
      "If you are at an office or shared network, you can ask the network administrator to run a scan across the network looking for misconfigured or infected devices.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cloudflare Ray ID: 646b7e2c3fe61e91\n",
      "â€¢\n",
      "Your IP: 24.97.110.217\n",
      "â€¢\n",
      "Performance & security by Cloudflare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #we went to office hours to investigate the \"no tables found\" error and he asked us to write this code\n",
    "# #to see what was happening\n",
    "\n",
    "# url = \"https://spotifycharts.com/regional/no/daily/2020-01-01\"\n",
    "# r = requests.get(url)\n",
    "# soup=BeautifulSoup(r.text, 'html.parser')\n",
    "# # df_list = pd.read_html(r.text) # this parses all the tables in webpages to a list\n",
    "# # df = df_list[0]\n",
    "# # df.head()\n",
    "# print(soup.find_all('table'))\n",
    "# print(soup.body.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 27/04/2021 06:13:50 PM : Extracting top 200 daily for 2020-01-01 - no\n",
      "ERROR : 27/04/2021 06:13:55 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-01/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:13:55 PM : Extracting top 200 daily for 2020-01-02 - no\n",
      "INFO : 27/04/2021 06:13:55 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:13:55 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:00 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-02/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:00 PM : Extracting top 200 daily for 2020-01-03 - no\n",
      "INFO : 27/04/2021 06:14:00 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:00 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:05 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-03/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:05 PM : Extracting top 200 daily for 2020-01-04 - no\n",
      "INFO : 27/04/2021 06:14:05 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:05 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:09 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-04/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:09 PM : Extracting top 200 daily for 2020-01-05 - no\n",
      "INFO : 27/04/2021 06:14:09 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:09 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:14 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-05/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:14 PM : Extracting top 200 daily for 2020-01-06 - no\n",
      "INFO : 27/04/2021 06:14:14 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:14 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:18 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-06/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:18 PM : Extracting top 200 daily for 2020-01-07 - no\n",
      "INFO : 27/04/2021 06:14:18 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:18 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:23 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-07/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:23 PM : Extracting top 200 daily for 2020-01-08 - no\n",
      "INFO : 27/04/2021 06:14:23 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:23 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:27 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-08/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:27 PM : Extracting top 200 daily for 2020-01-09 - no\n",
      "INFO : 27/04/2021 06:14:27 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:27 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:32 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-09/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:32 PM : Extracting top 200 daily for 2020-01-10 - no\n",
      "INFO : 27/04/2021 06:14:32 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:32 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:37 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-10/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:37 PM : Extracting top 200 daily for 2020-01-11 - no\n",
      "INFO : 27/04/2021 06:14:37 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:37 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:42 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-11/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:42 PM : Extracting top 200 daily for 2020-01-12 - no\n",
      "INFO : 27/04/2021 06:14:42 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:42 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:47 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-12/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:47 PM : Extracting top 200 daily for 2020-01-13 - no\n",
      "INFO : 27/04/2021 06:14:47 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:47 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:51 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-13/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:51 PM : Extracting top 200 daily for 2020-01-14 - no\n",
      "INFO : 27/04/2021 06:14:51 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:51 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:14:56 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-14/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:14:56 PM : Extracting top 200 daily for 2020-01-15 - no\n",
      "INFO : 27/04/2021 06:14:56 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:14:56 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:01 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-15/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:01 PM : Extracting top 200 daily for 2020-01-16 - no\n",
      "INFO : 27/04/2021 06:15:01 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:01 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:05 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-16/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:05 PM : Extracting top 200 daily for 2020-01-17 - no\n",
      "INFO : 27/04/2021 06:15:05 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:05 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:10 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-17/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:10 PM : Extracting top 200 daily for 2020-01-18 - no\n",
      "INFO : 27/04/2021 06:15:10 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:10 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:16 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-18/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:16 PM : Extracting top 200 daily for 2020-01-19 - no\n",
      "INFO : 27/04/2021 06:15:16 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:16 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:20 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-19/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:20 PM : Extracting top 200 daily for 2020-01-20 - no\n",
      "INFO : 27/04/2021 06:15:20 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:20 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:25 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-20/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:25 PM : Extracting top 200 daily for 2020-01-21 - no\n",
      "INFO : 27/04/2021 06:15:25 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:25 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:29 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-21/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:29 PM : Extracting top 200 daily for 2020-01-22 - no\n",
      "INFO : 27/04/2021 06:15:29 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:29 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:34 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-22/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:34 PM : Extracting top 200 daily for 2020-01-23 - no\n",
      "INFO : 27/04/2021 06:15:34 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:34 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:38 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-23/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:38 PM : Extracting top 200 daily for 2020-01-24 - no\n",
      "INFO : 27/04/2021 06:15:38 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:38 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:43 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-24/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:43 PM : Extracting top 200 daily for 2020-01-25 - no\n",
      "INFO : 27/04/2021 06:15:43 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:43 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:47 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-25/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:47 PM : Extracting top 200 daily for 2020-01-26 - no\n",
      "INFO : 27/04/2021 06:15:47 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:47 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:52 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-26/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:52 PM : Extracting top 200 daily for 2020-01-27 - no\n",
      "INFO : 27/04/2021 06:15:52 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:52 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:15:56 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-27/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:15:56 PM : Extracting top 200 daily for 2020-01-28 - no\n",
      "INFO : 27/04/2021 06:15:56 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:15:56 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:01 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-28/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:01 PM : Extracting top 200 daily for 2020-01-29 - no\n",
      "INFO : 27/04/2021 06:16:01 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:01 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:06 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-29/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:06 PM : Extracting top 200 daily for 2020-01-30 - no\n",
      "INFO : 27/04/2021 06:16:06 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:06 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:10 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-30/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:10 PM : Extracting top 200 daily for 2020-01-31 - no\n",
      "INFO : 27/04/2021 06:16:10 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:10 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:15 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-01-31/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:15 PM : Extracting top 200 daily for 2020-02-01 - no\n",
      "INFO : 27/04/2021 06:16:15 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:15 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:19 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-01/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:19 PM : Extracting top 200 daily for 2020-02-02 - no\n",
      "INFO : 27/04/2021 06:16:19 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:19 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:24 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-02/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:24 PM : Extracting top 200 daily for 2020-02-03 - no\n",
      "INFO : 27/04/2021 06:16:24 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:24 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:29 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-03/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:29 PM : Extracting top 200 daily for 2020-02-04 - no\n",
      "INFO : 27/04/2021 06:16:29 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:29 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:33 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-04/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:33 PM : Extracting top 200 daily for 2020-02-05 - no\n",
      "INFO : 27/04/2021 06:16:33 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:33 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:38 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-05/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:38 PM : Extracting top 200 daily for 2020-02-06 - no\n",
      "INFO : 27/04/2021 06:16:38 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:38 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:43 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-06/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:43 PM : Extracting top 200 daily for 2020-02-07 - no\n",
      "INFO : 27/04/2021 06:16:43 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:43 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:47 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-07/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:47 PM : Extracting top 200 daily for 2020-02-08 - no\n",
      "INFO : 27/04/2021 06:16:47 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:47 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:52 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-08/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:52 PM : Extracting top 200 daily for 2020-02-09 - no\n",
      "INFO : 27/04/2021 06:16:52 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:52 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:16:56 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-09/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:16:56 PM : Extracting top 200 daily for 2020-02-10 - no\n",
      "INFO : 27/04/2021 06:16:56 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:16:56 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:01 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-10/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:01 PM : Extracting top 200 daily for 2020-02-11 - no\n",
      "INFO : 27/04/2021 06:17:01 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:01 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:06 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-11/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:06 PM : Extracting top 200 daily for 2020-02-12 - no\n",
      "INFO : 27/04/2021 06:17:06 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:06 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:10 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-12/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:10 PM : Extracting top 200 daily for 2020-02-13 - no\n",
      "INFO : 27/04/2021 06:17:10 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:10 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:15 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-13/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:15 PM : Extracting top 200 daily for 2020-02-14 - no\n",
      "INFO : 27/04/2021 06:17:15 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:15 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:20 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-14/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:20 PM : Extracting top 200 daily for 2020-02-15 - no\n",
      "INFO : 27/04/2021 06:17:20 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:20 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:24 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-15/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:24 PM : Extracting top 200 daily for 2020-02-16 - no\n",
      "INFO : 27/04/2021 06:17:24 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:24 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:29 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-16/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:29 PM : Extracting top 200 daily for 2020-02-17 - no\n",
      "INFO : 27/04/2021 06:17:29 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:29 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:34 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-17/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:34 PM : Extracting top 200 daily for 2020-02-18 - no\n",
      "INFO : 27/04/2021 06:17:34 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:34 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:39 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-18/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:39 PM : Extracting top 200 daily for 2020-02-19 - no\n",
      "INFO : 27/04/2021 06:17:39 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:39 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:43 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-19/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:43 PM : Extracting top 200 daily for 2020-02-20 - no\n",
      "INFO : 27/04/2021 06:17:43 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:43 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:48 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-20/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:48 PM : Extracting top 200 daily for 2020-02-21 - no\n",
      "INFO : 27/04/2021 06:17:48 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:48 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:53 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-21/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:53 PM : Extracting top 200 daily for 2020-02-22 - no\n",
      "INFO : 27/04/2021 06:17:53 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:53 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:17:57 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-22/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:17:57 PM : Extracting top 200 daily for 2020-02-23 - no\n",
      "INFO : 27/04/2021 06:17:57 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:17:57 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:02 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-23/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:02 PM : Extracting top 200 daily for 2020-02-24 - no\n",
      "INFO : 27/04/2021 06:18:02 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:02 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:07 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-24/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:07 PM : Extracting top 200 daily for 2020-02-25 - no\n",
      "INFO : 27/04/2021 06:18:07 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:07 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:11 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-25/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:11 PM : Extracting top 200 daily for 2020-02-26 - no\n",
      "INFO : 27/04/2021 06:18:11 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:11 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:16 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-26/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:16 PM : Extracting top 200 daily for 2020-02-27 - no\n",
      "INFO : 27/04/2021 06:18:16 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:16 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:20 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-27/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:20 PM : Extracting top 200 daily for 2020-02-28 - no\n",
      "INFO : 27/04/2021 06:18:20 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:21 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:25 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-28/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:25 PM : Extracting top 200 daily for 2020-02-29 - no\n",
      "INFO : 27/04/2021 06:18:25 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:25 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:30 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-02-29/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:30 PM : Extracting top 200 daily for 2020-03-01 - no\n",
      "INFO : 27/04/2021 06:18:30 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:30 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:34 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-01/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:34 PM : Extracting top 200 daily for 2020-03-02 - no\n",
      "INFO : 27/04/2021 06:18:34 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:34 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:39 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-02/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:39 PM : Extracting top 200 daily for 2020-03-03 - no\n",
      "INFO : 27/04/2021 06:18:39 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:39 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:44 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-03/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:44 PM : Extracting top 200 daily for 2020-03-04 - no\n",
      "INFO : 27/04/2021 06:18:44 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:44 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:48 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-04/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:48 PM : Extracting top 200 daily for 2020-03-05 - no\n",
      "INFO : 27/04/2021 06:18:48 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:48 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:53 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-05/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:53 PM : Extracting top 200 daily for 2020-03-06 - no\n",
      "INFO : 27/04/2021 06:18:53 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:53 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:18:57 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-06/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:18:57 PM : Extracting top 200 daily for 2020-03-07 - no\n",
      "INFO : 27/04/2021 06:18:57 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:18:57 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:02 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-07/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:02 PM : Extracting top 200 daily for 2020-03-08 - no\n",
      "INFO : 27/04/2021 06:19:02 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:02 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:07 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-08/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:07 PM : Extracting top 200 daily for 2020-03-09 - no\n",
      "INFO : 27/04/2021 06:19:07 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:07 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:11 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-09/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:11 PM : Extracting top 200 daily for 2020-03-10 - no\n",
      "INFO : 27/04/2021 06:19:11 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:11 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:16 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-10/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:16 PM : Extracting top 200 daily for 2020-03-11 - no\n",
      "INFO : 27/04/2021 06:19:16 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:16 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:20 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-11/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:20 PM : Extracting top 200 daily for 2020-03-12 - no\n",
      "INFO : 27/04/2021 06:19:20 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:20 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:25 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-12/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:25 PM : Extracting top 200 daily for 2020-03-13 - no\n",
      "INFO : 27/04/2021 06:19:25 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:25 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:29 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-13/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:29 PM : Extracting top 200 daily for 2020-03-14 - no\n",
      "INFO : 27/04/2021 06:19:29 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:29 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:34 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-14/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:34 PM : Extracting top 200 daily for 2020-03-15 - no\n",
      "INFO : 27/04/2021 06:19:34 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:34 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:39 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-15/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:39 PM : Extracting top 200 daily for 2020-03-16 - no\n",
      "INFO : 27/04/2021 06:19:39 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:39 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:44 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-16/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:44 PM : Extracting top 200 daily for 2020-03-17 - no\n",
      "INFO : 27/04/2021 06:19:44 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:44 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:48 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-17/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:48 PM : Extracting top 200 daily for 2020-03-18 - no\n",
      "INFO : 27/04/2021 06:19:48 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:48 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:53 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-18/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:53 PM : Extracting top 200 daily for 2020-03-19 - no\n",
      "INFO : 27/04/2021 06:19:53 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:53 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:19:58 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-19/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:19:58 PM : Extracting top 200 daily for 2020-03-20 - no\n",
      "INFO : 27/04/2021 06:19:58 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:19:58 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:03 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-20/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:03 PM : Extracting top 200 daily for 2020-03-21 - no\n",
      "INFO : 27/04/2021 06:20:03 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:03 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:07 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-21/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:07 PM : Extracting top 200 daily for 2020-03-22 - no\n",
      "INFO : 27/04/2021 06:20:07 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:07 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:12 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-22/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:12 PM : Extracting top 200 daily for 2020-03-23 - no\n",
      "INFO : 27/04/2021 06:20:12 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:12 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:16 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-23/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:16 PM : Extracting top 200 daily for 2020-03-24 - no\n",
      "INFO : 27/04/2021 06:20:16 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:16 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:21 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-24/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:21 PM : Extracting top 200 daily for 2020-03-25 - no\n",
      "INFO : 27/04/2021 06:20:21 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:21 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:26 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-25/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:26 PM : Extracting top 200 daily for 2020-03-26 - no\n",
      "INFO : 27/04/2021 06:20:26 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:26 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:30 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-26/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:30 PM : Extracting top 200 daily for 2020-03-27 - no\n",
      "INFO : 27/04/2021 06:20:30 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:30 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:35 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-27/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:35 PM : Extracting top 200 daily for 2020-03-28 - no\n",
      "INFO : 27/04/2021 06:20:35 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:35 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:40 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-28/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:40 PM : Extracting top 200 daily for 2020-03-29 - no\n",
      "INFO : 27/04/2021 06:20:40 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:40 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:44 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-29/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:44 PM : Extracting top 200 daily for 2020-03-30 - no\n",
      "INFO : 27/04/2021 06:20:44 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:44 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:50 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-30/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:50 PM : Extracting top 200 daily for 2020-03-31 - no\n",
      "INFO : 27/04/2021 06:20:50 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:50 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:54 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-03-31/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:54 PM : Extracting top 200 daily for 2020-04-01 - no\n",
      "INFO : 27/04/2021 06:20:54 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:54 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:20:59 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-01/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:20:59 PM : Extracting top 200 daily for 2020-04-02 - no\n",
      "INFO : 27/04/2021 06:20:59 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:20:59 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:04 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-02/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:04 PM : Extracting top 200 daily for 2020-04-03 - no\n",
      "INFO : 27/04/2021 06:21:04 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:04 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:08 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-03/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:08 PM : Extracting top 200 daily for 2020-04-04 - no\n",
      "INFO : 27/04/2021 06:21:08 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:08 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:13 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-04/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:13 PM : Extracting top 200 daily for 2020-04-05 - no\n",
      "INFO : 27/04/2021 06:21:13 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:13 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:17 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-05/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:17 PM : Extracting top 200 daily for 2020-04-06 - no\n",
      "INFO : 27/04/2021 06:21:17 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:17 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:22 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-06/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:22 PM : Extracting top 200 daily for 2020-04-07 - no\n",
      "INFO : 27/04/2021 06:21:22 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:22 PM : Done appending to the file no_top_200_daily.csv!!!\n",
      "ERROR : 27/04/2021 06:21:26 PM : ***** <<HTTPSConnectionPool(host='spotifycharts.com', port=443): Max retries exceeded with url: /regional/no/daily/2020-04-07/download (Caused by ResponseError('too many 503 error responses'))>> Data not found. Generating empty dataframe *****\n",
      "INFO : 27/04/2021 06:21:26 PM : Extracting top 200 daily for 2020-04-08 - no\n",
      "INFO : 27/04/2021 06:21:26 PM : Appending data to the file no_top_200_daily.csv...\n",
      "INFO : 27/04/2021 06:21:26 PM : Done appending to the file no_top_200_daily.csv!!!\n"
     ]
    }
   ],
   "source": [
    "api=SpotifyCharts()\n",
    "api.top200Daily(output_file='no_top_200_daily.csv',start='2020-01-01',end='2020-12-31',region='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Track</th>\n",
       "      <th>Streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karantene  by TIX</td>\n",
       "      <td>124824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blinding Lights  by The Weeknd</td>\n",
       "      <td>120199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Svag  by Victor Leksell</td>\n",
       "      <td>118469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toosie Slide  by Drake</td>\n",
       "      <td>105361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roses - Imanbek Remix  by SAINt JHN</td>\n",
       "      <td>102318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2                                Track  \\\n",
       "0         NaN           1         NaN                    Karantene  by TIX   \n",
       "1         NaN           2         NaN       Blinding Lights  by The Weeknd   \n",
       "2         NaN           3         NaN              Svag  by Victor Leksell   \n",
       "3         NaN           4         NaN               Toosie Slide  by Drake   \n",
       "4         NaN           5         NaN  Roses - Imanbek Remix  by SAINt JHN   \n",
       "\n",
       "   Streams  \n",
       "0   124824  \n",
       "1   120199  \n",
       "2   118469  \n",
       "3   105361  \n",
       "4   102318  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cloudscraper\n",
    "\n",
    "scraper = cloudscraper.create_scraper()  # returns a CloudScraper instance\n",
    "# Or: scraper = cloudscraper.CloudScraper()  # CloudScraper inherits from requests.Session\n",
    "r=scraper.get(\"https://spotifycharts.com/regional/no/daily/2020-04-17\")\n",
    "df_list = pd.read_html(r.text) # this parses all the tables in webpages to a list\n",
    "df = df_list[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=get_table(\"https://spotifycharts.com/regional/no/daily/2020-04-17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>track</th>\n",
       "      <th>streams</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Karantene  by TIX</td>\n",
       "      <td>124824</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/6sMMfGxa9tB59dM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Blinding Lights  by The Weeknd</td>\n",
       "      <td>120199</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0VjIjW4GlUZAMYd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Svag  by Victor Leksell</td>\n",
       "      <td>118469</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/5SY5BWTxbDqFouu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Toosie Slide  by Drake</td>\n",
       "      <td>105361</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/127QTOFJsJQp5Lb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses - Imanbek Remix  by SAINt JHN</td>\n",
       "      <td>102318</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/24Yi9hE78yPEbZ4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Kaller PÃ¥ Deg  by TIX</td>\n",
       "      <td>94415</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0lnksmEu1sa7t16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kings &amp; Queens  by Ava Max</td>\n",
       "      <td>78550</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/76nqCfJOcFFWBJN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Like It Is  by Kygo, Zara Larsson, Tyga</td>\n",
       "      <td>77189</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/3frUvGrmGcay91l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Freedom  by Kygo, Zak Abel</td>\n",
       "      <td>76782</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/5Gj1wG8b12VQdEd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>End of Time  by K-391, Alan Walker, Ahrix</td>\n",
       "      <td>70723</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/67O8CWXxPsfz8or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>In Your Eyes  by The Weeknd</td>\n",
       "      <td>69741</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7szuecWAPwGoV1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Dance Monkey  by Tones And I</td>\n",
       "      <td>65778</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1rgnBhdG2JDFTbY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Blueberry Faygo  by Lil Mosey</td>\n",
       "      <td>64558</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/22LAwLoDA5b4AaG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>death bed (coffee for your head)  by Powfu, be...</td>\n",
       "      <td>62754</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7eJMfftS33KTjuF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bad Child  by Tones And I</td>\n",
       "      <td>62188</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1qCmZnC1FUpNgOy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>I'll Wait  by Kygo, Sasha Sloan</td>\n",
       "      <td>61221</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/6Q3K9gVUZRMZqZK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Don't Start Now  by Dua Lipa</td>\n",
       "      <td>60454</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/3PfIrDoz19wz7qK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Salt  by Ava Max</td>\n",
       "      <td>58345</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7vgv8KZBSo0TPzy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>ROCKSTAR (feat. Roddy Ricch)  by DaBaby</td>\n",
       "      <td>57968</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7ytR5pFWmSjzHJI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Josefine  by Herman Flesvig</td>\n",
       "      <td>57904</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/5xU6CXufU7wGRxs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Supalonely  by BENEE, Gus Dapperton</td>\n",
       "      <td>57280</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/4nK5YrxbMGZstTL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Someone You Loved  by Lewis Capaldi</td>\n",
       "      <td>51707</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7qEHsqek33rTcFN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>The Box  by Roddy Ricch</td>\n",
       "      <td>49428</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0nbXyq5TXYPCO7p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>If the World Was Ending - feat. Julia Michaels...</td>\n",
       "      <td>48881</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2kJwzbxV2ppxnQo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Heading Home  by Alan Walker, Ruben</td>\n",
       "      <td>48805</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/22O2Zdfj3jnJZDS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Boss Bitch  by Doja Cat</td>\n",
       "      <td>48690</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/78qd8dvwea0Gosb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Say So  by Doja Cat</td>\n",
       "      <td>48439</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/3Dv1eDb0MEgF93G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Haugenstua  by Herman Flesvig</td>\n",
       "      <td>48229</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0GFOW30WB6SsPoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Iâ€™m Ready (with Demi Lovato)  by Sam Smith</td>\n",
       "      <td>46136</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1fipvP2zmef6vN2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>DANCE  by CLMD, Tungevaag</td>\n",
       "      <td>45890</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/6TfeXwJihJRuBW3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Sunday Best  by Surfaces</td>\n",
       "      <td>43897</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1Cv1YLb4q0RzL6p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Break My Heart  by Dua Lipa</td>\n",
       "      <td>43823</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/017PF4Q3l4DBUiW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Physical  by Dua Lipa</td>\n",
       "      <td>42814</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/3AzjcOeAmA57TIO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>In Your Eyes (feat. Alida)  by Robin Schulz</td>\n",
       "      <td>42757</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/61ZM92T2zaXIVsq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Valhalla  by Ringnes-Ronny</td>\n",
       "      <td>39958</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1icRHA6kFSipRbZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Before You Go  by Lewis Capaldi</td>\n",
       "      <td>39933</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2gMXnyrvIjhVBUZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>JÃ¦vlig  by TIX</td>\n",
       "      <td>39597</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2Pckb69I4iMmL24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Intentions (feat. Quavo)  by Justin Bieber</td>\n",
       "      <td>39316</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/4umIPjkehX1r7uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Savage  by Megan Thee Stallion</td>\n",
       "      <td>39018</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/55CHeLEfn5iJ0II...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Alone, Pt. II  by Alan Walker, Ava Max</td>\n",
       "      <td>38024</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0bMbDctzMmTyK2j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>I Do  by Astrid S, Brett Young</td>\n",
       "      <td>37080</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/6yKkgZBuakFy6SP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>everything i wanted  by Billie Eilish</td>\n",
       "      <td>36422</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/3ZCTVFBt2Brf31R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>Skechers  by DripReport</td>\n",
       "      <td>34609</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2alc8VZAzDgdAsL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Bruises  by Lewis Capaldi</td>\n",
       "      <td>34457</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/4Of7rzpRpV1mWRb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>Det er fredag  by Herman Flesvig</td>\n",
       "      <td>33941</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/7g35s50bVXtkp6z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>Falling  by Trevor Daniel</td>\n",
       "      <td>33502</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2rRJrJEo19S2J82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>@ MEH  by Playboi Carti</td>\n",
       "      <td>33052</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/5UusfWUMMLEXLMc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Typen Din  by Vidar Villa</td>\n",
       "      <td>32408</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/0FF9IS0V311A2vM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Memories  by Maroon 5</td>\n",
       "      <td>31969</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/2b8fOow8UzyDFAE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Knockout  by Tungevaag</td>\n",
       "      <td>31365</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>https://open.spotify.com/track/1YFwmEAnSUx9ZAg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    position                                              track  streams  \\\n",
       "0          1                                  Karantene  by TIX   124824   \n",
       "1          2                     Blinding Lights  by The Weeknd   120199   \n",
       "2          3                            Svag  by Victor Leksell   118469   \n",
       "3          4                             Toosie Slide  by Drake   105361   \n",
       "4          5                Roses - Imanbek Remix  by SAINt JHN   102318   \n",
       "5          6                              Kaller PÃ¥ Deg  by TIX    94415   \n",
       "6          7                         Kings & Queens  by Ava Max    78550   \n",
       "7          8            Like It Is  by Kygo, Zara Larsson, Tyga    77189   \n",
       "8          9                         Freedom  by Kygo, Zak Abel    76782   \n",
       "9         10          End of Time  by K-391, Alan Walker, Ahrix    70723   \n",
       "10        11                        In Your Eyes  by The Weeknd    69741   \n",
       "11        12                       Dance Monkey  by Tones And I    65778   \n",
       "12        13                      Blueberry Faygo  by Lil Mosey    64558   \n",
       "13        14  death bed (coffee for your head)  by Powfu, be...    62754   \n",
       "14        15                          Bad Child  by Tones And I    62188   \n",
       "15        16                    I'll Wait  by Kygo, Sasha Sloan    61221   \n",
       "16        17                       Don't Start Now  by Dua Lipa    60454   \n",
       "17        18                                   Salt  by Ava Max    58345   \n",
       "18        19            ROCKSTAR (feat. Roddy Ricch)  by DaBaby    57968   \n",
       "19        20                        Josefine  by Herman Flesvig    57904   \n",
       "20        21                Supalonely  by BENEE, Gus Dapperton    57280   \n",
       "21        22                Someone You Loved  by Lewis Capaldi    51707   \n",
       "22        23                            The Box  by Roddy Ricch    49428   \n",
       "23        24  If the World Was Ending - feat. Julia Michaels...    48881   \n",
       "24        25                Heading Home  by Alan Walker, Ruben    48805   \n",
       "25        26                            Boss Bitch  by Doja Cat    48690   \n",
       "26        27                                Say So  by Doja Cat    48439   \n",
       "27        28                      Haugenstua  by Herman Flesvig    48229   \n",
       "28        29         Iâ€™m Ready (with Demi Lovato)  by Sam Smith    46136   \n",
       "29        30                          DANCE  by CLMD, Tungevaag    45890   \n",
       "30        31                           Sunday Best  by Surfaces    43897   \n",
       "31        32                        Break My Heart  by Dua Lipa    43823   \n",
       "32        33                              Physical  by Dua Lipa    42814   \n",
       "33        34        In Your Eyes (feat. Alida)  by Robin Schulz    42757   \n",
       "34        35                         Valhalla  by Ringnes-Ronny    39958   \n",
       "35        36                    Before You Go  by Lewis Capaldi    39933   \n",
       "36        37                                     JÃ¦vlig  by TIX    39597   \n",
       "37        38         Intentions (feat. Quavo)  by Justin Bieber    39316   \n",
       "38        39                     Savage  by Megan Thee Stallion    39018   \n",
       "39        40             Alone, Pt. II  by Alan Walker, Ava Max    38024   \n",
       "40        41                     I Do  by Astrid S, Brett Young    37080   \n",
       "41        42              everything i wanted  by Billie Eilish    36422   \n",
       "42        43                            Skechers  by DripReport    34609   \n",
       "43        44                          Bruises  by Lewis Capaldi    34457   \n",
       "44        45                   Det er fredag  by Herman Flesvig    33941   \n",
       "45        46                          Falling  by Trevor Daniel    33502   \n",
       "46        47                            @ MEH  by Playboi Carti    33052   \n",
       "47        48                          Typen Din  by Vidar Villa    32408   \n",
       "48        49                              Memories  by Maroon 5    31969   \n",
       "49        50                             Knockout  by Tungevaag    31365   \n",
       "\n",
       "         date                                                url  \n",
       "0  2020-04-17  https://open.spotify.com/track/6sMMfGxa9tB59dM...  \n",
       "1  2020-04-17  https://open.spotify.com/track/0VjIjW4GlUZAMYd...  \n",
       "2  2020-04-17  https://open.spotify.com/track/5SY5BWTxbDqFouu...  \n",
       "3  2020-04-17  https://open.spotify.com/track/127QTOFJsJQp5Lb...  \n",
       "4  2020-04-17  https://open.spotify.com/track/24Yi9hE78yPEbZ4...  \n",
       "5  2020-04-17  https://open.spotify.com/track/0lnksmEu1sa7t16...  \n",
       "6  2020-04-17  https://open.spotify.com/track/76nqCfJOcFFWBJN...  \n",
       "7  2020-04-17  https://open.spotify.com/track/3frUvGrmGcay91l...  \n",
       "8  2020-04-17  https://open.spotify.com/track/5Gj1wG8b12VQdEd...  \n",
       "9  2020-04-17  https://open.spotify.com/track/67O8CWXxPsfz8or...  \n",
       "10 2020-04-17  https://open.spotify.com/track/7szuecWAPwGoV1e...  \n",
       "11 2020-04-17  https://open.spotify.com/track/1rgnBhdG2JDFTbY...  \n",
       "12 2020-04-17  https://open.spotify.com/track/22LAwLoDA5b4AaG...  \n",
       "13 2020-04-17  https://open.spotify.com/track/7eJMfftS33KTjuF...  \n",
       "14 2020-04-17  https://open.spotify.com/track/1qCmZnC1FUpNgOy...  \n",
       "15 2020-04-17  https://open.spotify.com/track/6Q3K9gVUZRMZqZK...  \n",
       "16 2020-04-17  https://open.spotify.com/track/3PfIrDoz19wz7qK...  \n",
       "17 2020-04-17  https://open.spotify.com/track/7vgv8KZBSo0TPzy...  \n",
       "18 2020-04-17  https://open.spotify.com/track/7ytR5pFWmSjzHJI...  \n",
       "19 2020-04-17  https://open.spotify.com/track/5xU6CXufU7wGRxs...  \n",
       "20 2020-04-17  https://open.spotify.com/track/4nK5YrxbMGZstTL...  \n",
       "21 2020-04-17  https://open.spotify.com/track/7qEHsqek33rTcFN...  \n",
       "22 2020-04-17  https://open.spotify.com/track/0nbXyq5TXYPCO7p...  \n",
       "23 2020-04-17  https://open.spotify.com/track/2kJwzbxV2ppxnQo...  \n",
       "24 2020-04-17  https://open.spotify.com/track/22O2Zdfj3jnJZDS...  \n",
       "25 2020-04-17  https://open.spotify.com/track/78qd8dvwea0Gosb...  \n",
       "26 2020-04-17  https://open.spotify.com/track/3Dv1eDb0MEgF93G...  \n",
       "27 2020-04-17  https://open.spotify.com/track/0GFOW30WB6SsPoe...  \n",
       "28 2020-04-17  https://open.spotify.com/track/1fipvP2zmef6vN2...  \n",
       "29 2020-04-17  https://open.spotify.com/track/6TfeXwJihJRuBW3...  \n",
       "30 2020-04-17  https://open.spotify.com/track/1Cv1YLb4q0RzL6p...  \n",
       "31 2020-04-17  https://open.spotify.com/track/017PF4Q3l4DBUiW...  \n",
       "32 2020-04-17  https://open.spotify.com/track/3AzjcOeAmA57TIO...  \n",
       "33 2020-04-17  https://open.spotify.com/track/61ZM92T2zaXIVsq...  \n",
       "34 2020-04-17  https://open.spotify.com/track/1icRHA6kFSipRbZ...  \n",
       "35 2020-04-17  https://open.spotify.com/track/2gMXnyrvIjhVBUZ...  \n",
       "36 2020-04-17  https://open.spotify.com/track/2Pckb69I4iMmL24...  \n",
       "37 2020-04-17  https://open.spotify.com/track/4umIPjkehX1r7uh...  \n",
       "38 2020-04-17  https://open.spotify.com/track/55CHeLEfn5iJ0II...  \n",
       "39 2020-04-17  https://open.spotify.com/track/0bMbDctzMmTyK2j...  \n",
       "40 2020-04-17  https://open.spotify.com/track/6yKkgZBuakFy6SP...  \n",
       "41 2020-04-17  https://open.spotify.com/track/3ZCTVFBt2Brf31R...  \n",
       "42 2020-04-17  https://open.spotify.com/track/2alc8VZAzDgdAsL...  \n",
       "43 2020-04-17  https://open.spotify.com/track/4Of7rzpRpV1mWRb...  \n",
       "44 2020-04-17  https://open.spotify.com/track/7g35s50bVXtkp6z...  \n",
       "45 2020-04-17  https://open.spotify.com/track/2rRJrJEo19S2J82...  \n",
       "46 2020-04-17  https://open.spotify.com/track/5UusfWUMMLEXLMc...  \n",
       "47 2020-04-17  https://open.spotify.com/track/0FF9IS0V311A2vM...  \n",
       "48 2020-04-17  https://open.spotify.com/track/2b8fOow8UzyDFAE...  \n",
       "49 2020-04-17  https://open.spotify.com/track/1YFwmEAnSUx9ZAg...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
